{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as torch_models\n",
    "import os\n",
    "\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/jupyter/Kaggle/kaggle_grapheme')\n",
    "TRAIN_LABELS = path/'data/train.csv'\n",
    "TRAIN_IMG_FILES = path/'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_id               200840\n",
       "grapheme_root             168\n",
       "vowel_diacritic            11\n",
       "consonant_diacritic         7\n",
       "grapheme                 1295\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(do_flip=False,max_warp=0.,max_lighting=0.,p_lighting=0.)\n",
    "stats = ([0.0692], [0.2051])\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (ImageList\n",
    "        .from_df(df_train,path=TRAIN_IMG_FILES,cols=0,convert_mode='L',suffix='.png')\n",
    "        .split_by_rand_pct(seed=42)\n",
    "        .label_from_df(cols=['grapheme_root','vowel_diacritic','consonant_diacritic'])\n",
    "        .transform(tfms,size=(128,128),padding_mode='zeros')\n",
    "        .databunch(bs=64,num_workers=os.cpu_count()*4)\n",
    "        .normalize(stats)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.show_batch(rows=3,figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mish - \"Mish: A Self Regularized Non-Monotonic Neural Activation Function\"\n",
    "#https://arxiv.org/abs/1908.08681v1\n",
    "#implemented for PyTorch / FastAI by lessw2020 \n",
    "#github: https://github.com/lessw2020/mish\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #inlining this saves 1 second per epoch (V100 GPU) vs having a temp x and then returning x(!)\n",
    "        return x * (torch.tanh(F.softplus(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "\n",
    "1. Change the input conv_2d to take 1 channel grey scale image\n",
    "2. Transfer learning, copy first conv_2d weights to the new conv2d, aggregate 3 channel weights as suggested from stackoverflow / pytorch forum posts. (Note: Divide by 3 '(R+G+B)/3' does not have a effect if you think about back propogation, constant are just 1 ? However, I am not sure about the math)\n",
    "3. Multi - head: \n",
    "\n",
    "1. Inspired by APTOS and Retina net, it should be possible to output multi-results from the same backbone\n",
    "2. As suggested by DrHB https://www.kaggle.com/c/bengaliai-cv19/discussion/123432, the additional conv2d layer is to give each head a possibility to update weights before pooling\n",
    "3. Used AdaptiveConcatpool and standard fastai head structure\n",
    "4. Used Mish activatation function instead of ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Head(nn.Module):\n",
    "    def __init__(self,ni,nc,ps=0.25):\n",
    "        '''\n",
    "        ni : input filter size\n",
    "        nc : output class size\n",
    "        ps : dropout rate\n",
    "        '''\n",
    "        super().__init__()\n",
    "        layers = ([Mish(),conv2d(ni,ni),batchnorm_2d(ni),AdaptiveConcatPool2d(),Flatten()] \n",
    "                  + bn_drop_lin(ni*2,512,p=ps,actn=Mish()) \n",
    "                  + bn_drop_lin(512,nc,p=ps*2))\n",
    "        self.head = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,xb):\n",
    "        return self.head(xb)\n",
    "    \n",
    "class Resnet_1ch(nn.Module):\n",
    "    def __init__(self,arch,nc=[168,11,7],pretrained=True):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(*list(arch(pretrained=pretrained).children())[:-2])\n",
    "       \n",
    "        # change input filter size to 1\n",
    "        nf,ni,h,w = self.body[0].weight.shape\n",
    "        w = self.body[0].weight.sum(dim=1,keepdim=True)\n",
    "        conv_input = conv2d(1,nf,ks=h)\n",
    "        conv_input.weight.data = w\n",
    "        self.body[0] = conv_input\n",
    "        \n",
    "        # multi-head output\n",
    "        # 168,11,7 from num of unique labels\n",
    "        ni = num_features_model(self.body)\n",
    "        self.head_grapheme = Model_Head(ni,nc[0])\n",
    "        self.head_vowel = Model_Head(ni,nc[1])\n",
    "        self.head_consonant = Model_Head(ni,nc[2])\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.body(x)\n",
    "        return (self.head_grapheme(x),self.head_vowel(x),self.head_consonant(x))\n",
    "    \n",
    "# replace all relu layer with Mish        \n",
    "def to_mish(model):\n",
    "    for name,child in model.named_children():\n",
    "        if isinstance(child,nn.ReLU):\n",
    "            setattr(model,name,Mish())\n",
    "        else:\n",
    "            to_mish(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_multi_head(nn.Module):\n",
    "    def __init__(self,weights=[1,1,1]):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self,preds,target,reduction='mean'):\n",
    "        outp_1,outp_2,outp_3 = preds\n",
    "        outp_1,outp_2,outp_3 = outp_1.float(),outp_2.float(),outp_3.float()\n",
    "        target = target.long()\n",
    "        return (\n",
    "            weights[0] * F.cross_entropy(outp_1,target[:,0],reduction=reduction) \n",
    "            + weights[1] * F.cross_entropy(outp_2,target[:,1],reduction=reduction) \n",
    "            + weights[2] * F.cross_entropy(outp_3,target[:,2],reduction=reduction)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metric_grapheme = partial(Metric_idx,0)\n",
    "Metric_vowel = partial(Metric_idx,1)\n",
    "Metric_consonant = partial(Metric_idx,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /home/jupyter/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n",
      "100%|██████████| 83.3M/83.3M [00:02<00:00, 39.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = Resnet_1ch(torch_models.resnet34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = Loss_multi_head([0.5,0.25,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data,model,loss_func=loss_func,\n",
    "                metrics=[Metric_grapheme(),Metric_vowel(),Metric_consonant(),Metric_tot()],\n",
    "                model_dir=path/'models/resnet').to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
